#!/usr/bin/python3

################################################################################
#
# Copyright (c) 2022 Bequant S.L.
# All rights reserved.
#
# This product or document is proprietary to and embodies the
# confidential technology of Bequant S.L., Spain.
# Possession, use, duplication or distribution of this product
# or document is authorized only pursuant to a valid written
# license from Bequant S.L.
#
#
################################################################################

import json
import argparse
import datetime

import requests
if not requests.__version__.startswith("1."):
  # Avoid insecure warning when issuing REST queries
  import urllib3
  urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

from BillingSync import BillingSync

################################################################################

class SonarSync(BillingSync):

  ############################################################################

  def getAccounts(self, url, headers):
    page = 1
    remaining = True
    maxPerPage = 10000
    entries = []
    query = """query AccountQuery ($paginator: Paginator) {
    ip_assignment_histories(paginator: $paginator, removed_datetime: null) {
      entities {
        subnet
        ipassignmenthistoryable {
          ...on Account {
            id
            name
            account_status {
              id
              name
            }
            account_services {
              entities {
                service (type:DATA) {
                  id
                  name
                  }
                }
              }
            }
          }
        }
      }
    }"""

    while remaining:
      self.logger.info("POST to %s, page %d" % (url, page))
      payload = {
      "query": query,
        "variables": {
          "paginator": {
            "page": page,
            "records_per_page": maxPerPage
          }
        }
      }
      rsp = requests.post(url, headers=headers, data=self.jsonDumps(payload), verify=False)
      self.printResponseDetails(rsp)
      if rsp.status_code != 200:
        raise Exception("Bad query %d (page %d)" % (rsp.status_code, page))
      rspJson = json.loads(rsp.text)
      for e in rspJson["data"]["ip_assignment_histories"]["entities"]:
        entries.append(e)
      remaining = len(rspJson["data"]["ip_assignment_histories"]["entities"]) == maxPerPage
      page += 1

    return entries

  ############################################################################

  def getServices(self, url, headers):
    page = 1
    remaining = True
    maxPerPage = 10000
    entries = []
    query = """query ServiceQuery ($paginator: Paginator) {
    services (paginator: $paginator, type: DATA) {
      entities {
        id
        name
        type
        data_service_detail {
                    download_speed_kilobits_per_second
                    upload_speed_kilobits_per_second
        }
      }
    }
  }"""

    while remaining:
      self.logger.info("POST to %s, page %d" % (url, page))
      payload = {
      "query": query,
        "variables": {
          "paginator": {
            "page": page,
            "records_per_page": maxPerPage
          }
        }
      }
      rsp = requests.post(url, headers=headers, data=self.jsonDumps(payload), verify=False)
      self.printResponseDetails(rsp)
      if rsp.status_code != 200:
        raise Exception("Bad query %d (page %d)" % (rsp.status_code, page))
      rspJson = json.loads(rsp.text)
      for e in rspJson["data"]["services"]["entities"]:
        entries.append(e)
      remaining = len(rspJson["data"]["services"]["entities"]) == maxPerPage
      page += 1

    return entries

  ############################################################################

  def getDelinquents(self, url, headers):
    page = 1
    remaining = True
    maxPerPage = 10000
    entries = []
    query = """query DelinquentQuery($rrf: ReverseRelationFilter, $paginator: Paginator) {
    accounts(reverse_relation_filters: [$rrf], paginator: $paginator) {
      entities {
        id
        name
            account_status {
              name
            }
      }
    }
  }
  """

    while remaining:
      self.logger.info("POST to %s, page %d" % (url, page))
      payload = {
      "query": query,
        "variables": {
          "paginator": {
            "page": page,
            "records_per_page": maxPerPage
          },
          "rrf": {
              "relation": "invoices",
              "search": [
                {
                  "boolean_fields": [
                    {
                      "attribute": "delinquent",
                      "search_value": True
                    }
                  ]
                }
              ]
            }
        }
      }
      rsp = requests.post(url, headers=headers, data=self.jsonDumps(payload), verify=False)
      self.printResponseDetails(rsp)
      if rsp.status_code != 200:
        raise Exception("Bad query %d (page %d)" % (rspJson["status"], page))
      rspJson = json.loads(rsp.text)
      for e in rspJson["data"]["accounts"]["entities"]:
        entries.append(e)
      remaining = len(rspJson["data"]["accounts"]["entities"]) == maxPerPage
      page += 1

    return entries

  ############################################################################

  def getSites(self, url, headers):
    """
    Old Query. Empty response in two real deployments:

    query SitesQuery ($paginator: Paginator) {
    accounts (paginator: $paginator) {
      entities {
        id
        ip_assignments {
          entities {
            ipassignmentable {
              ...on InventoryItem {
                parent_inventory_item {
                  id
                  inventoryitemable {
                    ...on NetworkSite {
                      id
                      name
                    }
                  }
                }
              }
            }
          }
        }
      }
    }
    }
    
    Old query, including fields not used:

    query SitesQuery ($paginator: Paginator) {
      ip_assignments (paginator: $paginator) {
        entities {
          subnet
          ipassignmentable {
            id
            ... on InventoryModelFieldData {
              inventory_item {
                parent_inventory_item {
                  id
                  inventory_model_field_data {
                    entities {
                      ip_assignments {
                        entities {
                          subnet
                          description
                        }
                      }
                    }
                  }
                }
                inventoryitemable {
                  ... on Address {
                    addressable {
                      id
                      ... on Account {
                        name
                      }
                    }
                  }
                }
              }
            }
          }
        }
      }
    }
    """

    page = 1
    remaining = True
    maxPerPage = 10000
    entries = []
    query = """query SitesQuery ($paginator: Paginator) {
      ip_assignments (paginator: $paginator) {
        entities {
          subnet
          ipassignmentable {
            ... on InventoryModelFieldData {
              inventory_item {
                parent_inventory_item {
                  inventory_model_field_data {
                    entities {
                      ip_assignments {
                        entities {
                          description
                        }
                      }
                    }
                  }
                }
              }
            }
          }
        }
      }
    }
"""
  
    while remaining:
      self.logger.info("POST to %s, page %d" % (url, page))
      payload = {
      "query": query,
        "variables": {
          "paginator": {
            "page": page,
            "records_per_page": maxPerPage
          }
        }
      }
      rsp = requests.post(url, headers=headers, data=self.jsonDumps(payload), verify=False)
      self.printResponseDetails(rsp)
      if rsp.status_code != 200:
        raise Exception("Bad query %d (page %d)" % (rsp.status_code, page))
      rspJson = json.loads(rsp.text)
      for e in rspJson["data"]["ip_assignments"]["entities"]:
        # Add only entries with the information we are interested in (with a parent with description)
        # NOTE: if the query changes, some extra checks may be needed here.
        if self.fieldIsNotNull(e, ["ipassignmentable", "inventory_item", "parent_inventory_item", "inventory_model_field_data", "entities", "ip_assignments", "entities", "description"]):
          entries.append(e)
      remaining = len(rspJson["data"]["ip_assignments"]["entities"]) == maxPerPage
      page += 1

    return entries

  ############################################################################

  def getAddressInfo(self, addr, ipv6Mask=64):
    parts = addr.split('/')
    isV4 = "." in addr
    if len(parts) == 1:  # no mask
      if isV4:
        return 4, addr, 32
      else:
        return 6, addr, ipv6Mask
    elif len(parts) == 2:
      if isV4:
        return 4, parts[0], int(parts[1])
      else:
        return 6, parts[0], int(parts[1])
    raise Exception("Cannot split IP address %s, unexpected format" % addr)

  def normalizeData(self, accounts, services, delinquents, sites, dualStack, ipv6Mask):
    data = {'subscribers': [], 'policies': [], "subscriberGroups": []}
    subnetGroups = {}  # Structure to decide about address grouping
  
    # Policies
    #
    for s in services:
      data["policies"].append({
        "policyName": "%s-%s" % (s["name"], s["id"]),
        "policyId": s["id"], # s["name"]
        "sonarId": s["id"],
        "rateLimitDownlink": {"rate": int(s["data_service_detail"]["download_speed_kilobits_per_second"])},
        "rateLimitUplink": {"rate": int(s["data_service_detail"]["upload_speed_kilobits_per_second"])}
        })

    # Subscribers
    #
    for a in accounts:
      if not "ipassignmenthistoryable" in a or \
          not "account_services" in a["ipassignmenthistoryable"] or \
          not "entities" in a["ipassignmenthistoryable"]["account_services"]:
        continue
      # Get first not null service
      service = None
      for s in a["ipassignmenthistoryable"]["account_services"]["entities"]:
        if s["service"]:
          service = s["service"]
          break
      if not service:
        self.logger.debug("Account %s without services" % a["ipassignmenthistoryable"]["id"])
        continue
      matches = [x for x in data["policies"] if x["sonarId"] == service["id"]]
      if len(matches) == 1:
        policy = matches[0]
      else:
        self.logger.warning("Service not found (%s)" %  service["id"])
        continue

      if delinquents == None:
        blockStatus = a["ipassignmenthistoryable"]["account_status"]["name"] != "Active"
      else:
        matches = [x for x in delinquents if x["id"] == a["ipassignmenthistoryable"]["id"]]
        blockStatus = len(matches) != 0
        if blockStatus:
          self.logger.debug("Delinquent blocked %s" % a["ipassignmenthistoryable"]["name"])    

      # If IP address is IPv6 and without expected prefix, the subscriber is not created
      ipVersion, addr, mask = self.getAddressInfo(a["subnet"], ipv6Mask)
      if ipVersion == 4 or mask == ipv6Mask:
        data["subscribers"].append({
          "subscriberIp": addr,
          "subscriberId": a["ipassignmenthistoryable"]["name"],
          "policyRate" : policy["policyName"],
          "state": a["ipassignmenthistoryable"]["account_status"]["name"],
          "block": blockStatus
        })

      # Fill structure for dual stack grouping later on
      id = a["ipassignmenthistoryable"]["id"] 
      if not id in subnetGroups:
        subnetGroups[id] = {
          "subscriberId":  a["ipassignmenthistoryable"]["name"],
          "subnets": []
        }
      subnetGroups[id]["subnets"].append({"subnet": a["subnet"], "policyRate": policy["policyName"]})

    # Topology groups
    # We assume sites have been filtered so fields of interest always exist
    #
    siteGroups = {}
    for site in sites:
      for inventoryField in site["ipassignmentable"]["inventory_item"]["parent_inventory_item"]["inventory_model_field_data"]["entities"]:
        for ipAssignment in inventoryField["ip_assignments"]["entities"]:
          if self.fieldIsNotNull(ipAssignment, ["description"]):
            if not ipAssignment["description"] in siteGroups:
              siteGroups[ipAssignment["description"]] = [site["subnet"]]
            else:
              siteGroups[ipAssignment["description"]].append(site["subnet"])
    for siteName, siteMembers in siteGroups.items():
      subGroup = {}
      subGroup["subscriberGroupName"] = "L1-" + siteName
      subGroup["subscriberMembers"] = []
      subGroup["subscriberRanges"] = []
      for member in siteMembers:
        if "/" in member:
          subGroup["subscriberRanges"].append(member)
        else:
          subGroup["subscriberMembers"].append(member)
      data["subscriberGroups"].append(subGroup)

    # dual stack groups
    #
    if dualStack:
      for id, sng in subnetGroups.items():
        if len(sng["subnets"]) > 1:  # Subscriber with more than one address
          policy = sng["subnets"][0]["policyRate"]
          samePolicy = True
          for s in sng["subnets"]:
            if s["policyRate"] != policy:
              self.logger.debug("Subscriber %s with IPs %s with different policies" % (sng["subscriberId"], len(sng["subnets"])))
              samePolicy = False
              break
          if samePolicy:
            subGroup = {}
            subGroup["subscriberGroupName"] = "DS-%s" % sng["subscriberId"]
            subGroup["policyRate"] = policy
            subGroup["subscriberMembers"] = []
            for s in sng["subnets"]:
              ipVersion, addr, mask = self.getAddressInfo(s["subnet"], ipv6Mask)
              if ipVersion == 6 and mask != ipv6Mask:
                subGroup["subscriberRanges"] = ["%s/%s" % (addr, mask)]
              else:
               subGroup["subscriberMembers"].append(addr)
            data["subscriberGroups"].append(subGroup)

    return data

################################################################################

if __name__ == "__main__":

  parser = argparse.ArgumentParser(
    description="""
  Synchronizes speed limits in Sonar contracts with BQN rate policies.

  Requires an API KEY in Sonar and the REST API enabled in BQN.

  BQN Rate policies are identified by a unique name starting by "SN".
  BQN subscribers are identified by Sonar client "id".
  Accounts in status != "Active" have their traffic blocked by BQN (Sonar_block policy).

  Known limitations:
  - Multiple IP addresses in same contract not supported.
  - Synchronization may take several minutes.
  - If the synchronization fails, no retry is attempted (must be don e externally).
  - No scheduling of script execution (must be done externally).
  """, formatter_class=argparse.RawTextHelpFormatter)

  parser.add_argument('-b', help='BQN address and REST credentials. If absent, no BQN synchromization',
                      nargs=3, metavar=('BQN-IP', 'REST-USER', 'REST-PW'), dest='bqn')
  parser.add_argument('-v', '--verbose', action='count', dest='verbose', default=0,
                    help="Display extra informationt (repeat for increased verbosity)")
  parser.add_argument('-d', help='If present, blocking govered by delinquency',
                      dest='delinquent', action="store_true", default=False)
  parser.add_argument('-ds', '--dual-stack', action='store_true', dest="dualStack", default=False, 
     help='Group v4 and v6 IP addresses of same subscriber under same rate limit. Requires BQN R4.22 or later. If absent, no group created')
  parser.add_argument('-msk', '--v6-expected-mask', help='Expected IPv6 mask. 64 by default.',
               type=int, default=64, dest='ipv6Mask')
  parser.add_argument('server', metavar='SERVER', type=str, help="Billing server")
  parser.add_argument('key', metavar='API-KEY', type=str, help='Billing API key')
  args = parser.parse_args()

  billingSync = SonarSync(args.verbose)

  billingSync.logger.warning("%s synchronization script starts (v1.6)" % datetime.datetime.now())

  url = "https://" + args.server + "/api/graphql"
  headers = {
   "Authorization": "Bearer %s" % args.key,
   "Content-Type": "application/json",
   "Accept-Encoding": "chunked",
   "Connection": "keep-alive"
  }

  accounts = billingSync.getAccounts(url, headers)
  services = billingSync.getServices(url, headers)
  if args.delinquent:
    delinquents = billingSync.getDelinquents(url, headers)
  else:
    delinquents = None
  sites = billingSync.getSites(url, headers)
  
  data = billingSync.normalizeData(accounts, services, delinquents, sites, args.dualStack, args.ipv6Mask)
  billingSync.printData(data)
  if args.bqn:
    billingSync.updateBqn(args.bqn[0], args.bqn[1], args.bqn[2], data)

  billingSync.logger.warning("%s synchronization script ends" % datetime.datetime.now())
